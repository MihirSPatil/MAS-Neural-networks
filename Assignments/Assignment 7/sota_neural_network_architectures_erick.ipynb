{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-cpuOS8KvI3c"
   },
   "source": [
    "# Homework-  26.11.2018:\n",
    "## State of the Art Neural Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_zlJPravI3f"
   },
   "source": [
    "The purpose of this homework is to implement and evaluate the sota architectures presented in the lecture.\n",
    "However, you are encouraged to try your own layer module ideas.\n",
    "Feel free to consult the [Keras source code](https://github.com/keras-team/keras-applications):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAhETzsdvI3g"
   },
   "source": [
    "1. Based on the CNN modules presented in the lecture e.g. VGG16, Inception, ResNet, Xception, DenseNet, come up with your own CNN module and write a small text discussing your idea and motivations behind the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlP_HfdnvI3h"
   },
   "source": [
    "2. Evaluate all your module using the Keras CIFAR10 dataset splits (The model with best test accuracy will present their solution to the class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uh6u_ryjvI3j",
    "outputId": "fc54db61-13ea-4420-cf53-59b74e2d4023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KhhxDdmR7cth",
    "outputId": "5c5344a7-ca81-4486-c537-18a97a319658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'content/drive/My Drive': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls \"content/drive/My Drive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTL6httBvI3m"
   },
   "source": [
    "3. Evaluate your module using the FERPlus dataset (The model with the best test accuracy will present their solution to the class).\n",
    "\n",
    "    3.1 Download the [FER2013 dataset](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data) (images_path).\n",
    "    \n",
    "    3.2 Download the [FERPlus labels](https://github.com/Microsoft/FERPlus/blob/master/fer2013new.csv) (labels_path).\n",
    "    \n",
    "    3.3 Use the following code snippet to load the dataset giving the appropiate paths to the csv files downloaded in 3.1 and 3.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9hvq-SnvI3n"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.imshow(x_train[100])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDaIzsCEvI3q"
   },
   "outputs": [],
   "source": [
    "class FERPlus(object):\n",
    "    \"\"\"Class for loading FER2013 [1] emotion classification dataset with\n",
    "    the FERPlus labels [2]:\n",
    "    [1] kaggle.com/c/challenges-in-representation-learning-facial-\\\n",
    "            expression-recognition-challenge\n",
    "    [2] github.com/Microsoft/FERPlu://github.com/Microsoft/FERPlus\"\"\"\n",
    "\n",
    "    def __init__(self, images_path, labels_path, split='train', image_size=(48, 48),\n",
    "                 dataset_name='FERPlus'):\n",
    "\n",
    "        self.split = split\n",
    "        self.image_size = image_size\n",
    "        self.dataset_name = dataset_name\n",
    "        self.images_path = images_path\n",
    "        self.labels_path = labels_path\n",
    "        self.class_names = ['neutral', 'happiness', 'surprise', 'sadness',\n",
    "                            'anger', 'disgust', 'fear', 'contempt']\n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.arg_to_name = dict(zip(range(self.num_classes), self.class_names))\n",
    "        self.name_to_arg = dict(zip(self.class_names, range(self.num_classes)))\n",
    "        self._split_to_filter = {\n",
    "            'train': 'Training', 'val': 'PublicTest', 'test': 'PrivateTest'}\n",
    "\n",
    "    def load_data(self):\n",
    "        filter_name = self._split_to_filter[self.split]\n",
    "        pixel_sequences = pd.read_csv(self.images_path)\n",
    "        pixel_sequences = pixel_sequences[pixel_sequences.Usage == filter_name]\n",
    "        pixel_sequences = pixel_sequences['pixels'].tolist()\n",
    "        faces = []\n",
    "        for pixel_sequence in pixel_sequences:\n",
    "            face = [float(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(48, 48)\n",
    "            faces.append(cv2.resize(face, self.image_size))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "\n",
    "        emotions = pd.read_csv(self.labels_path)\n",
    "        emotions = emotions[emotions.Usage == filter_name]\n",
    "        emotions = emotions.iloc[:, 2:10].values\n",
    "        N = np.sum(emotions, axis=1)\n",
    "        mask = N != 0\n",
    "        N, faces, emotions = N[mask], faces[mask], emotions[mask]\n",
    "        emotions = emotions / np.expand_dims(N, 1)\n",
    "        return faces, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7922
    },
    "colab_type": "code",
    "id": "ZIkYdUey5KvT",
    "outputId": "b4f42e0a-c96b-420e-e3f3-240f3df39e4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28559, 48, 48, 1)\n",
      "(3573, 48, 48, 1)\n",
      "8\n",
      "x_train shape: (28559, 48, 48, 1)\n",
      "28559 train samples\n",
      "3573 test samples\n",
      "y_train shape: (28559, 8)\n",
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 48, 48, 16)   160         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 48, 48, 16)   64          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 48, 48, 16)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 48, 48, 16)   272         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 48, 48, 16)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 48, 48, 16)   64          dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 48, 48, 16)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 48, 48, 16)   2320        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 48, 48, 16)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 48, 48, 16)   64          dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 48, 48, 16)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 48, 48, 64)   1088        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 48, 48, 64)   1088        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 48, 48, 64)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 48, 48, 64)   0           conv2d_38[0][0]                  \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 48, 48, 64)   256         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 48, 48, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 48, 48, 16)   1040        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 48, 48, 16)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 48, 48, 16)   64          dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 48, 48, 16)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 48, 48, 16)   2320        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 48, 48, 16)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 48, 48, 16)   64          dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 48, 48, 16)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 48, 48, 64)   1088        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 48, 48, 64)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 48, 48, 64)   0           add_10[0][0]                     \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 48, 48, 64)   256         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 48, 48, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 48, 48, 16)   1040        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 48, 48, 16)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 48, 48, 16)   64          dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 48, 48, 16)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 48, 48, 16)   2320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 48, 48, 16)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 48, 48, 16)   64          dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 48, 48, 16)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 48, 48, 64)   1088        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 48, 48, 64)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 48, 48, 64)   0           add_11[0][0]                     \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 48, 48, 64)   256         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 48, 48, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 24, 24, 64)   4160        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 24, 24, 64)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 24, 24, 64)   256         dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 24, 24, 64)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 24, 24, 64)   36928       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 24, 24, 64)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 24, 24, 64)   256         dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 24, 24, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 24, 24, 128)  8320        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 24, 24, 128)  8320        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 24, 24, 128)  0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 24, 24, 128)  0           conv2d_48[0][0]                  \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 24, 24, 128)  512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 24, 24, 128)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 24, 24, 64)   8256        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 24, 24, 64)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 24, 24, 64)   256         dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 24, 24, 64)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 24, 24, 64)   36928       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 24, 24, 64)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 24, 24, 64)   256         dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 24, 24, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 24, 24, 128)  8320        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 24, 24, 128)  0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 24, 24, 128)  0           add_13[0][0]                     \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 24, 24, 128)  512         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 24, 24, 128)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 24, 24, 64)   8256        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 24, 24, 64)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 24, 24, 64)   256         dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 24, 24, 64)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 24, 24, 64)   36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 24, 24, 64)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 24, 24, 64)   256         dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 24, 24, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 24, 24, 128)  8320        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 24, 24, 128)  0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 24, 24, 128)  0           add_14[0][0]                     \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 24, 24, 128)  512         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 24, 24, 128)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 128)  16512       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 12, 12, 128)  0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 128)  512         dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 128)  147584      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 12, 12, 128)  0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 128)  512         dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 128)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 256)  33024       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 256)  33024       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 12, 12, 256)  0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 12, 12, 256)  0           conv2d_58[0][0]                  \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 256)  1024        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 256)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 128)  32896       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 12, 12, 128)  0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 128)  512         dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 128)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 128)  147584      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 12, 12, 128)  0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 128)  512         dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 256)  33024       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 12, 12, 256)  0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 12, 12, 256)  0           add_16[0][0]                     \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 256)  1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 256)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 128)  32896       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 12, 12, 128)  0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 128)  512         dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 128)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 128)  147584      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 12, 12, 128)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 128)  512         dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 128)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 256)  33024       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 12, 12, 256)  0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 12, 12, 1024) 263168      dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 12, 12, 1024) 0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 12, 12, 512)  524800      dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 12, 12, 512)  0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 256)  1179904     dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 6, 6, 256)    0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 6, 6, 256)    0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 6, 6, 256)    1024        dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 6, 6, 8)      18440       batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 8)            0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 8)            0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,832,456\n",
      "Trainable params: 2,827,240\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 611s 611ms/step - loss: 1.7608 - acc: 0.5300 - val_loss: 1.5120 - val_acc: 0.6048\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 589s 589ms/step - loss: 1.3438 - acc: 0.6810 - val_loss: 1.2915 - val_acc: 0.6972\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 590s 590ms/step - loss: 1.2275 - acc: 0.7197 - val_loss: 1.3084 - val_acc: 0.6977\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 592s 592ms/step - loss: 1.1718 - acc: 0.7379 - val_loss: 1.1427 - val_acc: 0.7305\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 588s 588ms/step - loss: 1.1333 - acc: 0.7525 - val_loss: 1.1248 - val_acc: 0.7375\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 592s 592ms/step - loss: 1.1130 - acc: 0.7596 - val_loss: 1.0825 - val_acc: 0.7476\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 591s 591ms/step - loss: 1.0920 - acc: 0.7663 - val_loss: 1.1497 - val_acc: 0.7347\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 589s 589ms/step - loss: 1.0797 - acc: 0.7706 - val_loss: 1.0603 - val_acc: 0.7702\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 592s 592ms/step - loss: 1.0689 - acc: 0.7753 - val_loss: 1.0581 - val_acc: 0.7604\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 590s 590ms/step - loss: 1.0608 - acc: 0.7792 - val_loss: 1.0764 - val_acc: 0.7674\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 589s 589ms/step - loss: 1.0532 - acc: 0.7817 - val_loss: 1.0938 - val_acc: 0.7680\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 592s 592ms/step - loss: 1.0514 - acc: 0.7818 - val_loss: 1.0676 - val_acc: 0.7503\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 587s 587ms/step - loss: 1.0457 - acc: 0.7844 - val_loss: 1.0766 - val_acc: 0.7671\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 594s 594ms/step - loss: 1.0402 - acc: 0.7888 - val_loss: 1.0376 - val_acc: 0.7708\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 593s 593ms/step - loss: 1.0362 - acc: 0.7889 - val_loss: 1.0231 - val_acc: 0.7817\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 593s 593ms/step - loss: 1.0344 - acc: 0.7906 - val_loss: 1.0328 - val_acc: 0.7725\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 593s 593ms/step - loss: 1.0296 - acc: 0.7926 - val_loss: 1.0122 - val_acc: 0.7823\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 593s 593ms/step - loss: 1.0276 - acc: 0.7929 - val_loss: 1.0501 - val_acc: 0.7669\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 591s 591ms/step - loss: 1.0237 - acc: 0.7955 - val_loss: 1.0469 - val_acc: 0.7708\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 593s 593ms/step - loss: 1.0238 - acc: 0.7960 - val_loss: 1.0813 - val_acc: 0.7573\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 592s 592ms/step - loss: 1.0193 - acc: 0.7967 - val_loss: 1.0477 - val_acc: 0.7646\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 593s 593ms/step - loss: 1.0200 - acc: 0.7969 - val_loss: 1.0558 - val_acc: 0.7657\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 591s 591ms/step - loss: 1.0173 - acc: 0.7984 - val_loss: 1.0401 - val_acc: 0.7867\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 593s 593ms/step - loss: 1.0148 - acc: 0.7996 - val_loss: 1.0204 - val_acc: 0.7811\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 592s 592ms/step - loss: 1.0129 - acc: 0.8000 - val_loss: 1.0175 - val_acc: 0.7825\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 592s 592ms/step - loss: 1.0136 - acc: 0.7983 - val_loss: 1.0329 - val_acc: 0.7769\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 589s 589ms/step - loss: 1.0105 - acc: 0.8000 - val_loss: 0.9804 - val_acc: 0.7909\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 593s 593ms/step - loss: 1.0083 - acc: 0.8018 - val_loss: 1.0088 - val_acc: 0.7912\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 589s 589ms/step - loss: 1.0066 - acc: 0.8030 - val_loss: 0.9897 - val_acc: 0.7926\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 591s 591ms/step - loss: 1.0071 - acc: 0.8006 - val_loss: 1.0072 - val_acc: 0.7739\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 588s 588ms/step - loss: 1.0066 - acc: 0.8028 - val_loss: 1.0056 - val_acc: 0.7926\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 590s 590ms/step - loss: 1.0035 - acc: 0.8036 - val_loss: 0.9991 - val_acc: 0.7848\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 588s 588ms/step - loss: 1.0012 - acc: 0.8051 - val_loss: 1.0036 - val_acc: 0.7960\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 590s 590ms/step - loss: 0.9998 - acc: 0.8041 - val_loss: 1.0010 - val_acc: 0.7839\n",
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 590s 590ms/step - loss: 0.9979 - acc: 0.8052 - val_loss: 0.9927 - val_acc: 0.7870\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 590s 590ms/step - loss: 0.9974 - acc: 0.8067 - val_loss: 0.9864 - val_acc: 0.7954\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 590s 590ms/step - loss: 0.9967 - acc: 0.8059 - val_loss: 1.0318 - val_acc: 0.7685\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 589s 589ms/step - loss: 0.9978 - acc: 0.8059 - val_loss: 0.9926 - val_acc: 0.7887\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 589s 589ms/step - loss: 0.9951 - acc: 0.8068 - val_loss: 1.0188 - val_acc: 0.7856\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9938 - acc: 0.8076 - val_loss: 1.0187 - val_acc: 0.7873\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9953 - acc: 0.8051 - val_loss: 1.0196 - val_acc: 0.7800\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9919 - acc: 0.8084 - val_loss: 1.0215 - val_acc: 0.7921\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9909 - acc: 0.8082 - val_loss: 0.9895 - val_acc: 0.7951\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9900 - acc: 0.8090 - val_loss: 1.0286 - val_acc: 0.7811\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9896 - acc: 0.8088 - val_loss: 0.9732 - val_acc: 0.7982\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 585s 585ms/step - loss: 0.9906 - acc: 0.8088 - val_loss: 1.0081 - val_acc: 0.7873\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9886 - acc: 0.8080 - val_loss: 1.0156 - val_acc: 0.7809\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9864 - acc: 0.8105 - val_loss: 0.9749 - val_acc: 0.8035\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9875 - acc: 0.8103 - val_loss: 1.0037 - val_acc: 0.7971\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 585s 585ms/step - loss: 0.9827 - acc: 0.8108 - val_loss: 1.0169 - val_acc: 0.7845\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9837 - acc: 0.8108 - val_loss: 0.9863 - val_acc: 0.7960\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 585s 585ms/step - loss: 0.9837 - acc: 0.8093 - val_loss: 0.9755 - val_acc: 0.8032\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9824 - acc: 0.8121 - val_loss: 0.9809 - val_acc: 0.7988\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 585s 585ms/step - loss: 0.9812 - acc: 0.8108 - val_loss: 0.9944 - val_acc: 0.7943\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 585s 585ms/step - loss: 0.9824 - acc: 0.8109 - val_loss: 1.0055 - val_acc: 0.7828\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 587s 587ms/step - loss: 0.9796 - acc: 0.8133 - val_loss: 0.9890 - val_acc: 0.7937\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9798 - acc: 0.8113 - val_loss: 0.9761 - val_acc: 0.7985\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 0.9814 - acc: 0.8126 - val_loss: 0.9860 - val_acc: 0.7993\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      " 665/1000 [==================>...........] - ETA: 3:15 - loss: 0.9764 - acc: 0.8147"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.layers import Convolution2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "import keras.utils\n",
    "import cv2\n",
    "from keras.models import Model\n",
    "# from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "from keras import backend as K\n",
    "# if K.backend()=='tensorflow':\n",
    "#     K.set_image_dim_ordering(\"th\")\n",
    "# Import Tensorflow with multiprocessing\n",
    "import tensorflow as tf\n",
    "import multiprocessing as mp\n",
    " \n",
    "# Loading the CIFAR-10 datasets\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas  as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "\n",
    "n = 3\n",
    "depth = n * 9 + 2\n",
    "\n",
    "FER_Data = FERPlus('drive/My Drive/Colab Notebooks/FERPlus_data/fer2013/fer2013.csv', \\\n",
    "                   'drive/My Drive/Colab Notebooks/FERPlus_data/FERPlus/fer2013new.csv',split='train')\n",
    "x_train, y_train = FER_Data.load_data()\n",
    "FER_Data = FERPlus('drive/My Drive/Colab Notebooks/FERPlus_data/fer2013/fer2013.csv', \\\n",
    "                   'drive/My Drive/Colab Notebooks/FERPlus_data/FERPlus/fer2013new.csv',split='test')\n",
    "x_test, y_test = FER_Data.load_data()\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(FER_Data.num_classes)\n",
    "num_classes = FER_Data.num_classes\n",
    "\n",
    "# # Load the CIFAR10 data.\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# num_classes = 10\n",
    "#------------ Preprocessing ------------\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255 \n",
    "x_test = x_test.astype('float32') / 255 \n",
    "\n",
    "# Substract mean\n",
    "x_train_mean = np.mean(x_train, axis=0)\n",
    "x_train -= x_train_mean\n",
    "x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# ----- Callbacks functions -----\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "# # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "# checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "#                              monitor='val_acc',\n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [lr_reducer, lr_scheduler]\n",
    "\n",
    "# Network Structure: \n",
    "#    1- Conv 32 feature maps with 3x3 with relu\n",
    "#    2- Conv 32 feature maps with 3x3 relu\n",
    "#    3- MaxPooling 2x2\n",
    "#    4- Dropout 25%\n",
    "#    5- Conv 64 feature maps with 3x3 relu\n",
    "#    6- Conv 64 feature maps with 3x3 relu\n",
    "#    7- MaxPooling layer with 2x2 \n",
    "#    8- Dropout 25%\n",
    "#    9- Flatten layer\n",
    "#   10- fully connected layer with 512 units and relu\n",
    "#   11- Dropout 25%\n",
    "#   12- Fully connected layer with 10 units and softmax\n",
    "# https://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/\n",
    "\n",
    "# Create the model\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "  \n",
    "num_filters_in = 16\n",
    "num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = resnet_layer(inputs=inputs,\n",
    "                 num_filters=num_filters_in,\n",
    "                 conv_first=True)\n",
    "\n",
    "for stage in range(3):\n",
    "    for res_block in range(num_res_blocks):\n",
    "        activation = 'relu'\n",
    "        batch_normalization = True\n",
    "        strides = 1\n",
    "        if stage == 0:\n",
    "            num_filters_out = num_filters_in * 4\n",
    "            if res_block == 0:  # first layer and first stage\n",
    "                activation = None\n",
    "                batch_normalization = False\n",
    "        else:\n",
    "            num_filters_out = num_filters_in * 2\n",
    "            if res_block == 0:  # first layer but not first stage\n",
    "                strides = 2    # downsample\n",
    "\n",
    "        # bottleneck residual unit\n",
    "        y = resnet_layer(inputs=x,\n",
    "                         num_filters=num_filters_in,\n",
    "                         kernel_size=1,\n",
    "                         strides=strides,\n",
    "                         activation=activation,\n",
    "                         batch_normalization=batch_normalization,\n",
    "                         conv_first=False)\n",
    "        y = Dropout(0.2)(y)\n",
    "        \n",
    "        y = resnet_layer(inputs=y,\n",
    "                         num_filters=num_filters_in,\n",
    "                         conv_first=False)\n",
    "        y = Dropout(0.2)(y)\n",
    "        \n",
    "        y = resnet_layer(inputs=y,\n",
    "                         num_filters=num_filters_out,\n",
    "                         kernel_size=1,\n",
    "                         conv_first=False)\n",
    "        y = Dropout(0.2)(y)\n",
    "        \n",
    "        if res_block == 0:\n",
    "            # linear projection residual shortcut connection to match\n",
    "            # changed dims\n",
    "            x = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=None,\n",
    "                             batch_normalization=False)\n",
    "            \n",
    "        x = keras.layers.add([x, y])\n",
    "\n",
    "    num_filters_in = num_filters_out\n",
    "\n",
    "# Add classifier on top\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = AveragePooling2D(pool_size=8)(x)\n",
    "x = MaxPooling2D(pool_size=8)(x)\n",
    "# y = Flatten()(x)\n",
    "y = Dense(1024, activation='relu', kernel_constraint=maxnorm(3))(y)\n",
    "y = Dropout(0.2)(y)\n",
    "y = Dense(512, activation='relu', kernel_constraint=maxnorm(3))(y)\n",
    "y = Dropout(0.2)(y)\n",
    "y = Convolution2D(filters=256, kernel_size=(3, 3), padding='same') (y)\n",
    "y = AveragePooling2D(pool_size=(2, 2), padding='same')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = BatchNormalization() (y)\n",
    "y = Convolution2D(filters=num_classes, \n",
    "                  kernel_size=(3, 3), \n",
    "                  padding='same')(y)\n",
    "y = GlobalAveragePooling2D()(y)\n",
    "outputs = Activation('softmax', name='predictions')(y)\n",
    "\n",
    "# outputs = Dense(num_classes,\n",
    "#                 activation ='softmax',\n",
    "#                 kernel_initializer='he_normal')(y)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "    # set input mean to 0 over the dataset\n",
    "    featurewise_center=False,\n",
    "    # set each sample mean to 0\n",
    "    samplewise_center=False,\n",
    "    # divide inputs by std of dataset\n",
    "    featurewise_std_normalization=False,\n",
    "    # divide each input by its std\n",
    "    samplewise_std_normalization=False,\n",
    "    # apply ZCA whitening\n",
    "    zca_whitening=False,\n",
    "    # epsilon for ZCA whitening\n",
    "    zca_epsilon=1e-06,\n",
    "    # randomly rotate images in the range (deg 0 to 180)\n",
    "    rotation_range=0,\n",
    "    # randomly shift images horizontally\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically\n",
    "    height_shift_range=0.1,\n",
    "    # set range for random shear\n",
    "    shear_range=0.,\n",
    "    # set range for random zoom\n",
    "    zoom_range=0.,\n",
    "    # set range for random channel shifts\n",
    "    channel_shift_range=0.,\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    # value used for fill_mode = \"constant\"\n",
    "    cval=0.,\n",
    "    # randomly flip images\n",
    "    horizontal_flip=True,\n",
    "    # randomly flip images\n",
    "    vertical_flip=False,\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,steps_per_epoch=1000,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7596
    },
    "colab_type": "code",
    "id": "Eqtpp8xxvI4E",
    "outputId": "f9051aad-f8d5-4f86-8dd9-d9c1d5e26172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 3, 32, 32)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 3, 32, 32)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 16, 32, 32)   448         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 16, 32, 32)   128         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 16, 32, 32)   0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 16, 32, 32)   272         activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 32, 32)   0           conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 16, 32, 32)   128         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 16, 32, 32)   0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 16, 32, 32)   2320        activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 32, 32)   0           conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 16, 32, 32)   128         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 16, 32, 32)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 64, 32, 32)   1088        activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 64, 32, 32)   1088        activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64, 32, 32)   0           conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 64, 32, 32)   0           conv2d_181[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 64, 32, 32)   128         add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 64, 32, 32)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 16, 32, 32)   1040        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 32, 32)   0           conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 16, 32, 32)   128         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 16, 32, 32)   0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 16, 32, 32)   2320        activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 32, 32)   0           conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 16, 32, 32)   128         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 16, 32, 32)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 64, 32, 32)   1088        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64, 32, 32)   0           conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 64, 32, 32)   0           add_49[0][0]                     \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 64, 32, 32)   128         add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 64, 32, 32)   0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 16, 32, 32)   1040        activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 32, 32)   0           conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 16, 32, 32)   128         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 16, 32, 32)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 16, 32, 32)   2320        activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 32, 32)   0           conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 16, 32, 32)   128         dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 16, 32, 32)   0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 64, 32, 32)   1088        activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 64, 32, 32)   0           conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 64, 32, 32)   0           add_50[0][0]                     \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 64, 32, 32)   128         add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 64, 32, 32)   0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 64, 16, 16)   4160        activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 64, 16, 16)   0           conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 64, 16, 16)   64          dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 64, 16, 16)   0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 64, 16, 16)   36928       activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 64, 16, 16)   0           conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 64, 16, 16)   64          dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 64, 16, 16)   0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 128, 16, 16)  8320        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 128, 16, 16)  8320        add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 128, 16, 16)  0           conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 128, 16, 16)  0           conv2d_191[0][0]                 \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 128, 16, 16)  64          add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 128, 16, 16)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 64, 16, 16)   8256        activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 64, 16, 16)   0           conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 64, 16, 16)   64          dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 64, 16, 16)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 64, 16, 16)   36928       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 64, 16, 16)   0           conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 64, 16, 16)   64          dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 64, 16, 16)   0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 128, 16, 16)  8320        activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 128, 16, 16)  0           conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 128, 16, 16)  0           add_52[0][0]                     \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 128, 16, 16)  64          add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 128, 16, 16)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 64, 16, 16)   8256        activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 64, 16, 16)   0           conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 64, 16, 16)   64          dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 64, 16, 16)   0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 64, 16, 16)   36928       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 64, 16, 16)   0           conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 64, 16, 16)   64          dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 64, 16, 16)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 128, 16, 16)  8320        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 128, 16, 16)  0           conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 128, 16, 16)  0           add_53[0][0]                     \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 128, 16, 16)  64          add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 128, 16, 16)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 128, 8, 8)    16512       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 128, 8, 8)    0           conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 128, 8, 8)    32          dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 128, 8, 8)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 128, 8, 8)    147584      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 128, 8, 8)    0           conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 128, 8, 8)    32          dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 128, 8, 8)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 256, 8, 8)    33024       activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 256, 8, 8)    33024       add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 256, 8, 8)    0           conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 256, 8, 8)    0           conv2d_201[0][0]                 \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 256, 8, 8)    32          add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 256, 8, 8)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 128, 8, 8)    32896       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 128, 8, 8)    0           conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 128, 8, 8)    32          dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 128, 8, 8)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 128, 8, 8)    147584      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 128, 8, 8)    0           conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 128, 8, 8)    32          dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 128, 8, 8)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 256, 8, 8)    33024       activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 256, 8, 8)    0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 256, 8, 8)    0           add_55[0][0]                     \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 256, 8, 8)    32          add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 256, 8, 8)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 128, 8, 8)    32896       activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 128, 8, 8)    0           conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 128, 8, 8)    32          dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 128, 8, 8)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 128, 8, 8)    147584      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 128, 8, 8)    0           conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 128, 8, 8)    32          dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 128, 8, 8)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 256, 8, 8)    33024       activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 256, 8, 8)    0           conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 256, 8, 8)    0           add_56[0][0]                     \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 256, 8, 8)    32          add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 256, 8, 8)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 256, 1, 1)    0           activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 256)          0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1024)         263168      flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1024)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          524800      dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 512)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           5130        dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,631,242\n",
      "Trainable params: 1,630,170\n",
      "Non-trainable params: 1,072\n",
      "__________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 336s 336ms/step - loss: 2.1289 - acc: 0.3178 - val_loss: 1.6277 - val_acc: 0.4749\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 1.5934 - acc: 0.4890 - val_loss: 1.3909 - val_acc: 0.5680\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 1.3653 - acc: 0.5788 - val_loss: 1.2874 - val_acc: 0.6002\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 1.2336 - acc: 0.6293 - val_loss: 1.1429 - val_acc: 0.6665\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 1.1421 - acc: 0.6629 - val_loss: 1.0553 - val_acc: 0.7009\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 1.0715 - acc: 0.6902 - val_loss: 1.1214 - val_acc: 0.6843\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 1.0253 - acc: 0.7090 - val_loss: 0.9585 - val_acc: 0.7334\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 317s 317ms/step - loss: 0.9716 - acc: 0.7282 - val_loss: 0.9505 - val_acc: 0.7432\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.9310 - acc: 0.7435 - val_loss: 0.8786 - val_acc: 0.7636\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 317s 317ms/step - loss: 0.8991 - acc: 0.7570 - val_loss: 0.9219 - val_acc: 0.7592\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.8690 - acc: 0.7673 - val_loss: 0.8124 - val_acc: 0.7924\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.8423 - acc: 0.7779 - val_loss: 0.7665 - val_acc: 0.8015\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.8247 - acc: 0.7843 - val_loss: 0.7593 - val_acc: 0.8065\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.8071 - acc: 0.7907 - val_loss: 0.7945 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.7902 - acc: 0.7966 - val_loss: 0.7278 - val_acc: 0.8221\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.7768 - acc: 0.8015 - val_loss: 0.7377 - val_acc: 0.8164\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.7651 - acc: 0.8066 - val_loss: 0.7414 - val_acc: 0.8229\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.7568 - acc: 0.8089 - val_loss: 0.7355 - val_acc: 0.8219\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.7447 - acc: 0.8137 - val_loss: 0.7157 - val_acc: 0.8330\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.7363 - acc: 0.8176 - val_loss: 0.6713 - val_acc: 0.8422\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.7275 - acc: 0.8205 - val_loss: 0.7199 - val_acc: 0.8260\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.7205 - acc: 0.8228 - val_loss: 0.6703 - val_acc: 0.8396\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.7162 - acc: 0.8244 - val_loss: 0.6812 - val_acc: 0.8399\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.7111 - acc: 0.8263 - val_loss: 0.6843 - val_acc: 0.8386\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 315s 315ms/step - loss: 0.7067 - acc: 0.8276 - val_loss: 0.6730 - val_acc: 0.8433\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 314s 314ms/step - loss: 0.6935 - acc: 0.8329 - val_loss: 0.6887 - val_acc: 0.8375\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 315s 315ms/step - loss: 0.6893 - acc: 0.8335 - val_loss: 0.6764 - val_acc: 0.8389\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 315s 315ms/step - loss: 0.6863 - acc: 0.8355 - val_loss: 0.6566 - val_acc: 0.8466\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 317s 317ms/step - loss: 0.6802 - acc: 0.8359 - val_loss: 0.6672 - val_acc: 0.8471\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.6757 - acc: 0.8386 - val_loss: 0.6554 - val_acc: 0.8485\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.6772 - acc: 0.8380 - val_loss: 0.6190 - val_acc: 0.8610\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 316s 316ms/step - loss: 0.6656 - acc: 0.8407 - val_loss: 0.6382 - val_acc: 0.8550\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      " 690/1000 [===================>..........] - ETA: 1:35 - loss: 0.6633 - acc: 0.8456"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-34e4b60880fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    302\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;31m# Final evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.utils import np_utils\n",
    "# from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "from keras import backend as K\n",
    "# if K.backend()=='tensorflow':\n",
    "#     K.set_image_dim_ordering(\"th\")\n",
    "# Import Tensorflow with multiprocessing\n",
    "import tensorflow as tf\n",
    "import multiprocessing as mp\n",
    " \n",
    "# Loading the CIFAR-10 datasets\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas  as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "n = 3\n",
    "depth = n * 9 + 2\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#------------ Preprocessing ------------\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255 \n",
    "x_test = x_test.astype('float32') / 255 \n",
    "\n",
    "# Substract mean\n",
    "x_train_mean = np.mean(x_train, axis=0)\n",
    "x_train -= x_train_mean\n",
    "x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# ----- Callbacks functions -----\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "# # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "# checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "#                              monitor='val_acc',\n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [lr_reducer, lr_scheduler]\n",
    "\n",
    "# Network Structure: \n",
    "#    1- Conv 32 feature maps with 3x3 with relu\n",
    "#    2- Conv 32 feature maps with 3x3 relu\n",
    "#    3- MaxPooling 2x2\n",
    "#    4- Dropout 25%\n",
    "#    5- Conv 64 feature maps with 3x3 relu\n",
    "#    6- Conv 64 feature maps with 3x3 relu\n",
    "#    7- MaxPooling layer with 2x2 \n",
    "#    8- Dropout 25%\n",
    "#    9- Flatten layer\n",
    "#   10- fully connected layer with 512 units and relu\n",
    "#   11- Dropout 25%\n",
    "#   12- Fully connected layer with 10 units and softmax\n",
    "# https://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/\n",
    "\n",
    "# Create the model\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "  \n",
    "num_filters_in = 16\n",
    "num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = resnet_layer(inputs=inputs,\n",
    "                 num_filters=num_filters_in,\n",
    "                 conv_first=True)\n",
    "\n",
    "for stage in range(3):\n",
    "    for res_block in range(num_res_blocks):\n",
    "        activation = 'relu'\n",
    "        batch_normalization = True\n",
    "        strides = 1\n",
    "        if stage == 0:\n",
    "            num_filters_out = num_filters_in * 4\n",
    "            if res_block == 0:  # first layer and first stage\n",
    "                activation = None\n",
    "                batch_normalization = False\n",
    "        else:\n",
    "            num_filters_out = num_filters_in * 2\n",
    "            if res_block == 0:  # first layer but not first stage\n",
    "                strides = 2    # downsample\n",
    "\n",
    "        # bottleneck residual unit\n",
    "        y = resnet_layer(inputs=x,\n",
    "                         num_filters=num_filters_in,\n",
    "                         kernel_size=1,\n",
    "                         strides=strides,\n",
    "                         activation=activation,\n",
    "                         batch_normalization=batch_normalization,\n",
    "                         conv_first=False)\n",
    "        y = Dropout(0.2)(y)\n",
    "        \n",
    "        y = resnet_layer(inputs=y,\n",
    "                         num_filters=num_filters_in,\n",
    "                         conv_first=False)\n",
    "        y = Dropout(0.2)(y)\n",
    "        \n",
    "        y = resnet_layer(inputs=y,\n",
    "                         num_filters=num_filters_out,\n",
    "                         kernel_size=1,\n",
    "                         conv_first=False)\n",
    "        y = Dropout(0.2)(y)\n",
    "        \n",
    "        if res_block == 0:\n",
    "            # linear projection residual shortcut connection to match\n",
    "            # changed dims\n",
    "            x = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=None,\n",
    "                             batch_normalization=False)\n",
    "            \n",
    "        x = keras.layers.add([x, y])\n",
    "\n",
    "    num_filters_in = num_filters_out\n",
    "\n",
    "# Add classifier on top\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = AveragePooling2D(pool_size=8)(x)\n",
    "x = MaxPooling2D(pool_size=8)(x)\n",
    "y = Flatten()(x)\n",
    "y = Dense(1024, activation='relu', kernel_constraint=maxnorm(3))(y)\n",
    "y = Dropout(0.2)(y)\n",
    "y = Dense(512, activation='relu', kernel_constraint=maxnorm(3))(y)\n",
    "y = Dropout(0.2)(y)\n",
    "\n",
    "outputs = Dense(num_classes,\n",
    "                activation ='softmax',\n",
    "                kernel_initializer='he_normal')(y)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "    # set input mean to 0 over the dataset\n",
    "    featurewise_center=False,\n",
    "    # set each sample mean to 0\n",
    "    samplewise_center=False,\n",
    "    # divide inputs by std of dataset\n",
    "    featurewise_std_normalization=False,\n",
    "    # divide each input by its std\n",
    "    samplewise_std_normalization=False,\n",
    "    # apply ZCA whitening\n",
    "    zca_whitening=False,\n",
    "    # epsilon for ZCA whitening\n",
    "    zca_epsilon=1e-06,\n",
    "    # randomly rotate images in the range (deg 0 to 180)\n",
    "    rotation_range=0,\n",
    "    # randomly shift images horizontally\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically\n",
    "    height_shift_range=0.1,\n",
    "    # set range for random shear\n",
    "    shear_range=0.,\n",
    "    # set range for random zoom\n",
    "    zoom_range=0.,\n",
    "    # set range for random channel shifts\n",
    "    channel_shift_range=0.,\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    # value used for fill_mode = \"constant\"\n",
    "    cval=0.,\n",
    "    # randomly flip images\n",
    "    horizontal_flip=True,\n",
    "    # randomly flip images\n",
    "    vertical_flip=False,\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,steps_per_epoch=1000,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7137
    },
    "colab_type": "code",
    "id": "qyOzFVR5vI4G",
    "outputId": "cd6b3cf9-e2ca-4c94-f615-15a421a3904d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 16)   64          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 16)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 16)   272         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 16)   64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 16)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 16)   2320        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 16)   64          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 16)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 64)   1088        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 64)   1088        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 64)   0           conv2d_36[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 16)   1040        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 16)   64          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 16)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 16)   2320        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 32, 16)   64          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 32, 32, 16)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 64)   1088        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 64)   0           add_10[0][0]                     \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 32, 64)   256         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 32, 32, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 16)   1040        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 16)   64          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 16)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 16)   2320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 16)   64          conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 16)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 64)   1088        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 64)   0           add_11[0][0]                     \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 64)   256         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 64)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 64)   4160        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 64)   256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 64)   36928       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 64)   256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 64)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 128)  8320        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 128)  8320        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 128)  0           conv2d_46[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 128)  512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 128)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 64)   8256        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 64)   256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 64)   36928       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 64)   256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 64)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 128)  8320        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 128)  0           add_13[0][0]                     \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 128)  512         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 128)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 64)   8256        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 64)   256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 64)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 64)   36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 64)   256         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 64)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 128)  8320        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 128)  0           add_14[0][0]                     \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 128)  512         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 128)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 128)    16512       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 128)    512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 128)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 128)    147584      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 128)    512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 128)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 256)    33024       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 256)    33024       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 256)    0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 256)    1024        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 256)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 128)    32896       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 128)    512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 128)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 128)    147584      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 128)    512         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 128)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 256)    33024       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 256)    0           add_16[0][0]                     \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 256)    1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 256)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 128)    32896       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 128)    512         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 128)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 128)    147584      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 128)    512         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 128)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 256)    33024       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 256)    0           add_17[0][0]                     \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 256)    1024        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 256)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 256)    0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 256)          0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           2570        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet29v2\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 216s 216ms/step - loss: 1.6375 - acc: 0.5708 - val_loss: 1.3220 - val_acc: 0.6612\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66120, saving model to /content/saved_models/cifar10_ResNet29v2_model.001.h5\n",
      "Epoch 2/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 1.1090 - acc: 0.7302 - val_loss: 1.3690 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.66120\n",
      "Epoch 3/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 0.9232 - acc: 0.7851 - val_loss: 1.3250 - val_acc: 0.6638\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.66120 to 0.66380, saving model to /content/saved_models/cifar10_ResNet29v2_model.003.h5\n",
      "Epoch 4/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 0.8154 - acc: 0.8156 - val_loss: 0.9601 - val_acc: 0.7692\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.66380 to 0.76920, saving model to /content/saved_models/cifar10_ResNet29v2_model.004.h5\n",
      "Epoch 5/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 204s 204ms/step - loss: 0.7485 - acc: 0.8344 - val_loss: 1.0252 - val_acc: 0.7506\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.76920\n",
      "Epoch 6/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.6888 - acc: 0.8506 - val_loss: 1.0265 - val_acc: 0.7492\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.76920\n",
      "Epoch 7/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 0.6496 - acc: 0.8625 - val_loss: 1.0028 - val_acc: 0.7641\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.76920\n",
      "Epoch 8/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 0.6164 - acc: 0.8708 - val_loss: 0.9921 - val_acc: 0.7647\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.76920\n",
      "Epoch 9/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.5948 - acc: 0.8769 - val_loss: 0.8792 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.76920 to 0.79250, saving model to /content/saved_models/cifar10_ResNet29v2_model.009.h5\n",
      "Epoch 10/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.5724 - acc: 0.8840 - val_loss: 0.9296 - val_acc: 0.7756\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.79250\n",
      "Epoch 11/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 210s 210ms/step - loss: 0.5561 - acc: 0.8890 - val_loss: 0.7333 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.79250 to 0.83710, saving model to /content/saved_models/cifar10_ResNet29v2_model.011.h5\n",
      "Epoch 12/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 0.5356 - acc: 0.8952 - val_loss: 0.7258 - val_acc: 0.8346\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.83710\n",
      "Epoch 13/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.5194 - acc: 0.8995 - val_loss: 0.7706 - val_acc: 0.8334\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.83710\n",
      "Epoch 14/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.5119 - acc: 0.9011 - val_loss: 0.6853 - val_acc: 0.8489\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.83710 to 0.84890, saving model to /content/saved_models/cifar10_ResNet29v2_model.014.h5\n",
      "Epoch 15/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.4971 - acc: 0.9064 - val_loss: 0.8354 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.84890\n",
      "Epoch 16/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.4897 - acc: 0.9079 - val_loss: 0.9022 - val_acc: 0.8007\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.84890\n",
      "Epoch 17/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.4774 - acc: 0.9123 - val_loss: 1.0560 - val_acc: 0.7740\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.84890\n",
      "Epoch 18/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 0.4705 - acc: 0.9148 - val_loss: 0.7089 - val_acc: 0.8516\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.84890 to 0.85160, saving model to /content/saved_models/cifar10_ResNet29v2_model.018.h5\n",
      "Epoch 19/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.4638 - acc: 0.9159 - val_loss: 0.6604 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.85160 to 0.86300, saving model to /content/saved_models/cifar10_ResNet29v2_model.019.h5\n",
      "Epoch 20/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.4584 - acc: 0.9175 - val_loss: 0.6628 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.86300\n",
      "Epoch 21/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 0.4517 - acc: 0.9200 - val_loss: 0.8620 - val_acc: 0.8243\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.86300\n",
      "Epoch 22/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.4475 - acc: 0.9207 - val_loss: 0.7778 - val_acc: 0.8341\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.86300\n",
      "Epoch 23/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.4413 - acc: 0.9231 - val_loss: 0.6732 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.86300\n",
      "Epoch 24/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 0.4354 - acc: 0.9239 - val_loss: 0.8865 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.86300\n",
      "Epoch 25/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 0.4333 - acc: 0.9252 - val_loss: 0.9132 - val_acc: 0.8168\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.86300\n",
      "Epoch 26/50\n",
      "Learning rate:  0.001\n",
      "1000/1000 [==============================] - 206s 206ms/step - loss: 0.4228 - acc: 0.9288 - val_loss: 0.7270 - val_acc: 0.8496\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.86300\n",
      "Epoch 27/50\n",
      "Learning rate:  0.001\n",
      " 145/1000 [===>..........................] - ETA: 2:52 - loss: 0.4307 - acc: 0.9241"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2fc70d9ece25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    411\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;31m# Score trained model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Trains a ResNet on the CIFAR10 dataset.\n",
    "ResNet v1\n",
    "[a] Deep Residual Learning for Image Recognition\n",
    "https://arxiv.org/pdf/1512.03385.pdf\n",
    "ResNet v2\n",
    "[b] Identity Mappings in Deep Residual Networks\n",
    "https://arxiv.org/pdf/1603.05027.pdf\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
    "epochs = 50\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 3\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 2\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,steps_per_epoch=1000,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1556
    },
    "colab_type": "code",
    "id": "gveTtWadvI4N",
    "outputId": "b5da9807-ceba-4835-b7ee-3471b2bda078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAFyCAYAAACKkcLXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c4340a550>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAGNCAYAAAB9ginvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n73kZd+Xj1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c43323128>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000\n",
      "1 1000\n",
      "2 1000\n",
      "3 1000\n",
      "4 1000\n",
      "5 1000\n",
      "6 1000\n",
      "7 1000\n",
      "8 1000\n",
      "9 1000\n",
      "[[877   5  46   0  10   0  12   3  24  23]\n",
      " [  4 894   1   0   1   0   5   1   8  86]\n",
      " [ 20   2 833   4  42  18  65  12   2   2]\n",
      " [  9   5  51 508  92 151 136  19   5  24]\n",
      " [  7   1  22   1 908  15  33  12   0   1]\n",
      " [  6   1  21  22  40 840  48  16   0   6]\n",
      " [  4   0  18   1   8   0 962   1   2   4]\n",
      " [  3   0  12   4  46  32  17 879   0   7]\n",
      " [ 66   7   8   0   2   1   5   3 875  33]\n",
      " [ 10  21   2   1   1   0   6   4   7 948]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGfCAYAAACX9jKsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCH0ihQvQgghhNArUrwIIYQQQq/8P10TmbCAX6KjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c433179e8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# sequential_model_to_ascii_printout(model2)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas  as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(model.history.history.keys())\n",
    "plt.figure(0)\n",
    "plt.plot(model.history.history['acc'],'r')\n",
    "plt.plot(model.history.history['val_acc'],'g')\n",
    "plt.xticks(np.arange(0, 101, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "plt.legend(['train','validation'])\n",
    " \n",
    "plt.figure(1)\n",
    "plt.plot(model.history.history['loss'],'r')\n",
    "plt.plot(model.history.history['val_loss'],'g')\n",
    "plt.xticks(np.arange(0, 101, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.legend(['train','validation'])\n",
    " \n",
    "plt.show()\n",
    "\n",
    "\n",
    "Y_pred = model.predict(x_test, verbose=2)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    " \n",
    "for ix in range(10):\n",
    "    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\n",
    "cm = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\n",
    "print(cm)\n",
    " \n",
    "# Visualizing of confusion matrix\n",
    " \n",
    "df_cm = pd.DataFrame(cm, range(10),\n",
    "                  range(10))\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 12})# font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0Vk1QAgVF8E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EUfnQBuavI4Q"
   },
   "source": [
    "## Models\n",
    "* InceptionV3\n",
    "* DenseNet\n",
    "* NasNet\n",
    "\n",
    "## Hyperparameters\n",
    "* Dense layer size\n",
    "* Dropout probability\n",
    "* Number of fixed layers\n",
    "* Learning rate \n",
    "* decay schedule\n",
    "* batch size\n",
    "* epochs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sota_neural_network_architectures.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
